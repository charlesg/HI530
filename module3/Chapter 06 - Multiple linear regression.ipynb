{"cells":[{"cell_type":"markdown","source":"# Chapter 6: Multiple Linear Regression\n\n> (c) 2019 Galit Shmueli, Peter C. Bruce, Peter Gedeck \n>\n> Code included in\n>\n> _Data Mining for Business Analytics: Concepts, Techniques, and Applications in Python_ (First Edition) \n> Galit Shmueli, Peter C. Bruce, Peter Gedeck, and Nitin R. Patel. 2019.\n\n## Import required packages","metadata":{"cell_id":"00000-4d3a227e-010c-4afb-b4eb-8b9976145831","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00001-ceac52e1-d21d-4edd-b840-f0a0a8eb4bce","deepnote_cell_type":"code"},"source":"%matplotlib inline\nfrom pathlib import Path\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, BayesianRidge\nimport statsmodels.formula.api as sm\nimport matplotlib.pylab as plt\n\nfrom dmba import regressionSummary, exhaustive_search\nfrom dmba import backward_elimination, forward_selection, stepwise_selection\nfrom dmba import adjusted_r2_score, AIC_score, BIC_score\n","outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.3","metadata":{"cell_id":"00002-163866e1-fee8-483d-9317-95f2cd6c7c4c","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"scrolled":false,"cell_id":"00003-4e819462-c2e2-44cf-85f1-bb2c98410d2f","deepnote_cell_type":"code"},"source":"# Reduce data frame to the top 1000 rows and select columns for regression analysis\ncar_df = pd.read_csv('ToyotaCorolla.csv')\ncar_df = car_df.iloc[0:1000]\n\npredictors = ['Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Met_Color', 'Automatic', 'CC', \n              'Doors', 'Quarterly_Tax', 'Weight']\noutcome = 'Price'\n\n# partition data\nX = pd.get_dummies(car_df[predictors], drop_first=True)\ny = car_df[outcome]\ntrain_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n\ncar_lm = LinearRegression()\ncar_lm.fit(train_X, train_y)\n\n# print coefficients\nprint('intercept ', car_lm.intercept_)\nprint(pd.DataFrame({'Predictor': X.columns, 'coefficient': car_lm.coef_}))\n\n# print performance measures\nregressionSummary(train_y, car_lm.predict(train_X))","outputs":[{"name":"stdout","output_type":"stream","text":"intercept  -1319.3543800411844\n           Predictor  coefficient\n0          Age_08_04  -140.748761\n1                 KM    -0.017840\n2                 HP    36.103419\n3          Met_Color    84.281830\n4          Automatic   416.781954\n5                 CC     0.017737\n6              Doors   -50.657863\n7      Quarterly_Tax    13.625325\n8             Weight    13.038711\n9   Fuel_Type_Diesel  1066.464681\n10  Fuel_Type_Petrol  2310.249543\n\nRegression statistics\n\n                      Mean Error (ME) : 0.0000\n       Root Mean Squared Error (RMSE) : 1400.5823\n            Mean Absolute Error (MAE) : 1046.9072\n          Mean Percentage Error (MPE) : -1.0223\nMean Absolute Percentage Error (MAPE) : 9.2994\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00004-33c4d8b0-2124-40af-8d01-45f349b83090","deepnote_cell_type":"code"},"source":"pred_y = car_lm.predict(train_X)\n\nprint('adjusted r2 : ', adjusted_r2_score(train_y, pred_y, car_lm))\nprint('AIC : ', AIC_score(train_y, pred_y, car_lm))\nprint('BIC : ', BIC_score(train_y, pred_y, car_lm))","outputs":[{"name":"stdout","output_type":"stream","text":"adjusted r2 :  0.8537958550253093\nAIC :  10422.298278332171\nBIC :  10479.45836384998\n"}],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.4","metadata":{"cell_id":"00005-e8c27f55-dc47-415b-be97-1ce00c27ff21","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00006-219a2af1-b070-4db5-87ce-365e4435f848","deepnote_cell_type":"code"},"source":"# Use predict() to make predictions on a new set\ncar_lm_pred = car_lm.predict(valid_X)\n\nresult = pd.DataFrame({'Predicted': car_lm_pred, 'Actual': valid_y,\n                       'Residual': valid_y - car_lm_pred})\nprint(result.head(20))\n\n# Compute common accuracy measures\nregressionSummary(valid_y, car_lm_pred)","outputs":[{"name":"stdout","output_type":"stream","text":"        Predicted  Actual     Residual\n507  10607.333940   11500   892.666060\n818   9272.705792    8950  -322.705792\n452  10617.947808   11450   832.052192\n368  13600.396275   11450 -2150.396275\n242  12396.694660   11950  -446.694660\n929   9496.498212    9995   498.501788\n262  12480.063217   13500  1019.936783\n810   8834.146068    7950  -884.146068\n318  12183.361282    9900 -2283.361282\n49   19206.965683   21950  2743.034317\n446  10987.498309   11950   962.501691\n142  18501.527375   19950  1448.472625\n968   9914.690947    9950    35.309053\n345  13827.299932   14950  1122.700068\n971   7966.732543   10495  2528.267457\n133  17185.242041   15950 -1235.242041\n104  19952.658062   19450  -502.658062\n6    16570.609280   16900   329.390720\n600  13739.409113   11250 -2489.409113\n496  11267.513740   11750   482.486260\n\nRegression statistics\n\n                      Mean Error (ME) : 103.6803\n       Root Mean Squared Error (RMSE) : 1312.8523\n            Mean Absolute Error (MAE) : 1017.5972\n          Mean Percentage Error (MPE) : -0.2633\nMean Absolute Percentage Error (MAPE) : 9.0111\n"}],"execution_count":null},{"cell_type":"markdown","source":"## Figure 6.1\nDetermine the residuals and create a histogram","metadata":{"cell_id":"00007-142b94aa-b8c6-4332-b5f5-0e7f1089b9e1","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00008-99f0e228-8f49-4d28-be81-a2a8c4014252","deepnote_cell_type":"code"},"source":"car_lm_pred = car_lm.predict(valid_X)\nall_residuals = valid_y - car_lm_pred\n\n# Determine the percentage of datapoints with a residual in [-1406, 1406] = approx. 75\\%\nprint(len(all_residuals[(all_residuals > -1406) & (all_residuals < 1406)]) / len(all_residuals))\n\nax = pd.DataFrame({'Residuals': all_residuals}).hist(bins=25)\n\nplt.tight_layout()\nplt.show()","outputs":[{"name":"stdout","output_type":"stream","text":"0.7425\n"},{"data":{"image/png":"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\n","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.5\nRun an exhaustive search. The Fuel type column is categorical and needs to be converted into dummy variables.","metadata":{"cell_id":"00009-72cd4f0b-d559-4c1d-ac92-b82b122520c0","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00010-08852b92-b790-42cc-9050-29dc911b36cc","deepnote_cell_type":"code"},"source":"def train_model(variables):\n    model = LinearRegression()\n    model.fit(train_X[variables], train_y)\n    return model\n\ndef score_model(model, variables):\n    pred_y = model.predict(train_X[variables])\n    # we negate as score is optimized to be as low as possible\n    return -adjusted_r2_score(train_y, pred_y, model)\n\nallVariables = train_X.columns\nresults = exhaustive_search(allVariables, train_model, score_model)\n\ndata = []\nfor result in results:\n    model = result['model']\n    variables = result['variables']\n    AIC = AIC_score(train_y, model.predict(train_X[variables]), model)\n    \n    d = {'n': result['n'], 'r2adj': -result['score'], 'AIC': AIC}\n    d.update({var: var in result['variables'] for var in allVariables})\n    data.append(d)\npd.set_option('display.width', 100)\nprint(pd.DataFrame(data, columns=('n', 'r2adj', 'AIC') + tuple(sorted(allVariables))))\npd.reset_option('display.width')","outputs":[{"name":"stdout","output_type":"stream","text":"     n     r2adj           AIC  Age_08_04  Automatic     CC  Doors  Fuel_Type_Diesel  \\\n0    1  0.767901  10689.712094       True      False  False  False             False   \n1    2  0.801160  10597.910645       True      False  False  False             False   \n2    3  0.829659  10506.084235       True      False  False  False             False   \n3    4  0.846357  10445.174820       True      False  False  False             False   \n4    5  0.849044  10435.578836       True      False  False  False             False   \n5    6  0.853172  10419.932278       True      False  False  False             False   \n6    7  0.853860  10418.104025       True      False  False  False              True   \n7    8  0.854297  10417.290103       True       True  False  False              True   \n8    9  0.854172  10418.789079       True       True  False   True              True   \n9   10  0.854036  10420.330800       True       True  False   True              True   \n10  11  0.853796  10422.298278       True       True   True   True              True   \n\n    Fuel_Type_Petrol     HP     KM  Met_Color  Quarterly_Tax  Weight  \n0              False  False  False      False          False   False  \n1              False   True  False      False          False   False  \n2              False   True  False      False          False    True  \n3              False   True   True      False          False    True  \n4              False   True   True      False           True    True  \n5               True   True   True      False           True    True  \n6               True   True   True      False           True    True  \n7               True   True   True      False           True    True  \n8               True   True   True      False           True    True  \n9               True   True   True       True           True    True  \n10              True   True   True       True           True    True  \n"}],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.6 backward elimination","metadata":{"cell_id":"00011-67647286-7e09-44fd-a004-499c2439796e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00012-431e3460-d421-4570-bc43-962a92ed8f98","deepnote_cell_type":"code"},"source":"def train_model(variables):\n    model = LinearRegression()\n    model.fit(train_X[variables], train_y)\n    return model\n\ndef score_model(model, variables):\n    return AIC_score(train_y, model.predict(train_X[variables]), model)\n\nbest_model, best_variables = backward_elimination(train_X.columns, train_model, score_model, verbose=True)\n\nprint(best_variables)","outputs":[{"name":"stdout","output_type":"stream","text":"Variables: Age_08_04, KM, HP, Met_Color, Automatic, CC, Doors, Quarterly_Tax, Weight, Fuel_Type_Diesel, Fuel_Type_Petrol\nStart: score=10422.30\nStep: score=10420.33, remove CC\nStep: score=10418.79, remove Met_Color\nStep: score=10417.29, remove Doors\nStep: score=10417.29, remove None\n['Age_08_04', 'KM', 'HP', 'Automatic', 'Quarterly_Tax', 'Weight', 'Fuel_Type_Diesel', 'Fuel_Type_Petrol']\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00013-d29e4684-5123-4da6-8f9f-c18c4da6ada4","deepnote_cell_type":"code"},"source":"regressionSummary(valid_y, best_model.predict(valid_X[best_variables]))","outputs":[{"name":"stdout","output_type":"stream","text":"\nRegression statistics\n\n                      Mean Error (ME) : 103.3045\n       Root Mean Squared Error (RMSE) : 1314.4844\n            Mean Absolute Error (MAE) : 1016.8875\n          Mean Percentage Error (MPE) : -0.2700\nMean Absolute Percentage Error (MAPE) : 8.9984\n"}],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.7 Forward selection","metadata":{"cell_id":"00014-d328595a-589b-42e5-ab88-8307818e89b0","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00015-40ede774-eff9-4a2c-8c63-b9d995f33fbd","deepnote_cell_type":"code"},"source":"# The initial model is the constant model - this requires special handling\n# in train_model and score_model\ndef train_model(variables):\n    if len(variables) == 0:\n        return None\n    model = LinearRegression()\n    model.fit(train_X[variables], train_y)\n    return model\n\ndef score_model(model, variables):\n    if len(variables) == 0:\n        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n    return AIC_score(train_y, model.predict(train_X[variables]), model)\n\nbest_model, best_variables = forward_selection(train_X.columns, train_model, score_model, verbose=True)\n\nprint(best_variables)","outputs":[{"name":"stdout","output_type":"stream","text":"Variables: Age_08_04, KM, HP, Met_Color, Automatic, CC, Doors, Quarterly_Tax, Weight, Fuel_Type_Diesel, Fuel_Type_Petrol\nStart: score=11565.07, constant\nStep: score=10689.71, add Age_08_04\nStep: score=10597.91, add HP\nStep: score=10506.08, add Weight\nStep: score=10445.17, add KM\nStep: score=10435.58, add Quarterly_Tax\nStep: score=10419.93, add Fuel_Type_Petrol\nStep: score=10418.10, add Fuel_Type_Diesel\nStep: score=10417.29, add Automatic\nStep: score=10417.29, add None\n['Age_08_04', 'HP', 'Weight', 'KM', 'Quarterly_Tax', 'Fuel_Type_Petrol', 'Fuel_Type_Diesel', 'Automatic']\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00016-7fd82c9b-9eff-4d20-a6ca-6f1abc74118a","deepnote_cell_type":"code"},"source":"best_model, best_variables = stepwise_selection(train_X.columns, train_model, score_model, verbose=True)\n\nprint(best_variables)","outputs":[{"name":"stdout","output_type":"stream","text":"Variables: Age_08_04, KM, HP, Met_Color, Automatic, CC, Doors, Quarterly_Tax, Weight, Fuel_Type_Diesel, Fuel_Type_Petrol\nStart: score=11565.07, constant\nStep: score=10689.71, add Age_08_04\nStep: score=10597.91, add HP\nStep: score=10506.08, add Weight\nStep: score=10445.17, add KM\nStep: score=10435.58, add Quarterly_Tax\nStep: score=10419.93, add Fuel_Type_Petrol\nStep: score=10418.10, add Fuel_Type_Diesel\nStep: score=10417.29, add Automatic\nStep: score=10417.29, unchanged None\n['Age_08_04', 'HP', 'Weight', 'KM', 'Quarterly_Tax', 'Fuel_Type_Petrol', 'Fuel_Type_Diesel', 'Automatic']\n"}],"execution_count":null},{"cell_type":"markdown","source":"## Table XX regularized methods","metadata":{"cell_id":"00017-1bdff60f-e4dd-44e9-9140-8f35eb509900","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00018-bfe15c30-1d4c-4565-b3d8-a45bd2efe92b","deepnote_cell_type":"code"},"source":"lasso = Lasso(normalize=True, alpha=1)\nlasso.fit(train_X, train_y)\nregressionSummary(valid_y, lasso.predict(valid_X))\n\nlasso_cv = LassoCV(normalize=True, cv=5)\nlasso_cv.fit(train_X, train_y)\nregressionSummary(valid_y, lasso_cv.predict(valid_X))\nprint('Lasso-CV chosen regularization: ', lasso_cv.alpha_)\nprint(lasso_cv.coef_)\n\nridge = Ridge(normalize=True, alpha=1)\nridge.fit(train_X, train_y)\nregressionSummary(valid_y, ridge.predict(valid_X))\n\nbayesianRidge = BayesianRidge(normalize=True)\nbayesianRidge.fit(train_X, train_y)\nregressionSummary(valid_y, bayesianRidge.predict(valid_X))\nprint('Bayesian ridge chosen regularization: ', bayesianRidge.lambda_ / bayesianRidge.alpha_)","outputs":[{"name":"stdout","output_type":"stream","text":"\nRegression statistics\n\n                      Mean Error (ME) : 120.6311\n       Root Mean Squared Error (RMSE) : 1332.2752\n            Mean Absolute Error (MAE) : 1021.5286\n          Mean Percentage Error (MPE) : -0.2364\nMean Absolute Percentage Error (MAPE) : 9.0115\n\nRegression statistics\n\n                      Mean Error (ME) : 145.1571\n       Root Mean Squared Error (RMSE) : 1397.9428\n            Mean Absolute Error (MAE) : 1052.4649\n          Mean Percentage Error (MPE) : -0.2966\nMean Absolute Percentage Error (MAPE) : 9.2918\nLasso-CV chosen regularization:  3.5138446691310588\n[-1.40370575e+02 -1.76669006e-02  3.38674037e+01  0.00000000e+00\n  6.94393427e+01  0.00000000e+00  0.00000000e+00  2.70913468e+00\n  1.24342596e+01 -0.00000000e+00  0.00000000e+00]\n\nRegression statistics\n\n                      Mean Error (ME) : 154.3286\n       Root Mean Squared Error (RMSE) : 1879.7426\n            Mean Absolute Error (MAE) : 1353.2735\n          Mean Percentage Error (MPE) : -2.3897\nMean Absolute Percentage Error (MAPE) : 11.1309\n\nRegression statistics\n\n                      Mean Error (ME) : 105.5382\n       Root Mean Squared Error (RMSE) : 1313.0217\n            Mean Absolute Error (MAE) : 1017.2356\n          Mean Percentage Error (MPE) : -0.2703\nMean Absolute Percentage Error (MAPE) : 9.0012\nBayesian ridge chosen regularization:  0.004622833440097622\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00019-2fb34af5-81fc-402f-a80f-7cf81aa4fa9f","deepnote_cell_type":"code"},"source":"linearRegression = LinearRegression(normalize=True).fit(train_X, train_y)\nregressionSummary(valid_y, linearRegression.predict(valid_X))","outputs":[{"name":"stdout","output_type":"stream","text":"\nRegression statistics\n\n                      Mean Error (ME) : 103.6803\n       Root Mean Squared Error (RMSE) : 1312.8523\n            Mean Absolute Error (MAE) : 1017.5972\n          Mean Percentage Error (MPE) : -0.2633\nMean Absolute Percentage Error (MAPE) : 9.0111\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00020-6dd9da74-29d6-466e-b71a-aaceb7c28068","deepnote_cell_type":"code"},"source":"pd.DataFrame({'features': train_X.columns, 'linear regression': linearRegression.coef_, \n              'lassoCV': lasso_cv.coef_, 'bayesianRidge': bayesianRidge.coef_})","outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>linear regression</th>\n      <th>lassoCV</th>\n      <th>bayesianRidge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Age_08_04</td>\n      <td>-140.748761</td>\n      <td>-140.370575</td>\n      <td>-139.754059</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KM</td>\n      <td>-0.017840</td>\n      <td>-0.017667</td>\n      <td>-0.018131</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HP</td>\n      <td>36.103419</td>\n      <td>33.867404</td>\n      <td>35.856074</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Met_Color</td>\n      <td>84.281830</td>\n      <td>0.000000</td>\n      <td>85.088966</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Automatic</td>\n      <td>416.781954</td>\n      <td>69.439343</td>\n      <td>408.599781</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CC</td>\n      <td>0.017737</td>\n      <td>0.000000</td>\n      <td>0.020405</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Doors</td>\n      <td>-50.657863</td>\n      <td>0.000000</td>\n      <td>-47.917629</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Quarterly_Tax</td>\n      <td>13.625325</td>\n      <td>2.709135</td>\n      <td>13.269979</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Weight</td>\n      <td>13.038711</td>\n      <td>12.434260</td>\n      <td>13.114412</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Fuel_Type_Diesel</td>\n      <td>1066.464681</td>\n      <td>-0.000000</td>\n      <td>955.581484</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Fuel_Type_Petrol</td>\n      <td>2310.249543</td>\n      <td>0.000000</td>\n      <td>2162.115762</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"            features  linear regression     lassoCV  bayesianRidge\n0          Age_08_04        -140.748761 -140.370575    -139.754059\n1                 KM          -0.017840   -0.017667      -0.018131\n2                 HP          36.103419   33.867404      35.856074\n3          Met_Color          84.281830    0.000000      85.088966\n4          Automatic         416.781954   69.439343     408.599781\n5                 CC           0.017737    0.000000       0.020405\n6              Doors         -50.657863    0.000000     -47.917629\n7      Quarterly_Tax          13.625325    2.709135      13.269979\n8             Weight          13.038711   12.434260      13.114412\n9   Fuel_Type_Diesel        1066.464681   -0.000000     955.581484\n10  Fuel_Type_Petrol        2310.249543    0.000000    2162.115762"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"markdown","source":"## Table 6.10","metadata":{"cell_id":"00021-02ff1344-9dae-4b4c-9dd3-ede2d2cabdc4","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"scrolled":false,"cell_id":"00022-60253386-b1d8-403a-8f2e-489ab8493d39","deepnote_cell_type":"code"},"source":"# run a linear regression of Price on the remaining 11 predictors in the training set\ntrain_df = train_X.join(train_y)\n\npredictors = train_X.columns\nformula = 'Price ~ ' + ' + '.join(predictors)\n\ncar_lm = sm.ols(formula=formula, data=train_df).fit()\nprint(car_lm.summary())","outputs":[{"name":"stdout","output_type":"stream","text":"                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  Price   R-squared:                       0.856\nModel:                            OLS   Adj. R-squared:                  0.854\nMethod:                 Least Squares   F-statistic:                     319.0\nDate:                Sun, 07 Apr 2019   Prob (F-statistic):          1.73e-239\nTime:                        13:53:06   Log-Likelihood:                -5198.1\nNo. Observations:                 600   AIC:                         1.042e+04\nDf Residuals:                     588   BIC:                         1.047e+04\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------------\nIntercept        -1319.3544   1728.427     -0.763      0.446   -4713.997    2075.288\nAge_08_04         -140.7488      5.142    -27.374      0.000    -150.847    -130.650\nKM                  -0.0178      0.002     -7.286      0.000      -0.023      -0.013\nHP                  36.1034      5.321      6.785      0.000      25.653      46.554\nMet_Color           84.2818    127.005      0.664      0.507    -165.158     333.721\nAutomatic          416.7820    259.794      1.604      0.109     -93.454     927.018\nCC                   0.0177      0.099      0.179      0.858      -0.177       0.213\nDoors              -50.6579     65.187     -0.777      0.437    -178.686      77.371\nQuarterly_Tax       13.6253      2.518      5.411      0.000       8.680      18.571\nWeight              13.0387      1.602      8.140      0.000       9.893      16.185\nFuel_Type_Diesel  1066.4647    527.285      2.023      0.044      30.872    2102.057\nFuel_Type_Petrol  2310.2495    521.045      4.434      0.000    1286.914    3333.585\n==============================================================================\nOmnibus:                       62.422   Durbin-Watson:                   1.899\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              366.046\nSkew:                           0.186   Prob(JB):                     3.27e-80\nKurtosis:                       6.808   Cond. No.                     2.20e+06\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.2e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00023-669e90c2-77bb-47a4-8a72-0e83c451d06c","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=52e9ae2e-8d42-48c9-9988-588f5a262306' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"deepnote_notebook_id":"c2445828-c935-4a69-8845-d2ccd26d46ce","deepnote":{},"deepnote_execution_queue":[]}}